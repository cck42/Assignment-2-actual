#if lambdas are entered, use them
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
#find the best lambda, nrow(data)/10)
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
browser()
y_test <- as.numeric(test_set %*% ridge + rnorm(n, sd=5))
browser()
y_train <- tcrossprod(train_set, ridge)
mse <- apply((y_train - y_test)^2, 2, mean)
best_lambda <- lambdas[which.min(mse)]
ridge[best_lambda*10,]
}
ridge(X_test, y_test)
browser()
ridge(X_test, y_test)
y_test
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
#find the best lambda by cross-validation
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
browser()
#y_test <- as.numeric(test_set %*% ridge + rnorm(n, sd=5))
y_test <- tcrossprod(test_set, ridge)
browser()
y_train <- tcrossprod(train_set, ridge)
mse <- apply((y_train - y_test)^2, 2, mean)
best_lambda <- lambdas[which.min(mse)]
ridge[best_lambda*10,]
}
ridge(X_test, y_test)
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
#find the best lambda by cross-validation
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
#y_test <- as.numeric(test_set %*% ridge + rnorm(n, sd=5))
y_test <- tcrossprod(test_set, ridge)
browser()
y_train <- tcrossprod(train_set, ridge)
browser()
mse <- apply((y_train - y_test)^2, 2, mean)
best_lambda <- lambdas[which.min(mse)]
ridge[best_lambda*10,]
}
ridge(X_test, y_test)
y_train
y_test
?lm.ridge
typeof(Sepal.Length ~ ., iris)
typeof(Sepal.Length ~ .)
attributes((Sepal.Length ~ .))
f <- y ~ x + b
length(f)
f[1]
f[2]
f[3]
attributes((f[3]))
class(f[3])
ySet <- train_set[form[2]]
test_set <- X[test_rows,]
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
ySet <- train_set[form[2],]
xSet <- setdiff(train_set, ySet)
ridge(xSet, ySet)
}
ridge_regress(Sepal.Length ~ ., iris)
type(f[2])
typeof(f[2])
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
ySet <- train_set[as.character(form[2],)]
xSet <- setdiff(train_set, ySet)
ridge(xSet, ySet)
}
ridge_regress(Sepal.Length ~ ., iris)
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
ySet <- train_set[as.character(form[2]),]
xSet <- setdiff(train_set, ySet)
ridge(xSet, ySet)
}
ridge_regress(Sepal.Length ~ ., iris)
?model.matrix
ff <- log(Volume) ~ log(Height) + log(Girth)
utils::str(m <- model.frame(ff, trees))
mat <- model.matrix(ff, m)
mat
ff
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- y[train_rows,]
ridge(train_set, y_train_set)
}
ridge_regress(Sepal.Length ~ ., iris)
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- y[train_rows]
ridge(train_set, y_train_set)
}
ridge_regress(Sepal.Length ~ ., iris)
y_test
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
#find the best lambda by cross-validation
#test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
#test_set <- X[test_rows,]
#train_rows <- setdiff(seq_len(nrow(X)), test_rows)
#train_set <- X[train_rows,]
#y_test <- as.numeric(test_set %*% ridge + rnorm(n, sd=5))
#y_test <- tcrossprod(test_set, ridge)
#browser()
#y_train <- tcrossprod(train_set, ridge)
#browser()
#mse <- apply((y_train - y_test)^2, 2, mean)
#best_lambda <- lambdas[which.min(mse)]
ridge[best_lambda*10,]
}
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- y[train_rows]
ridge(train_set, y_train_set)
}
ridge_regress(Sepal.Length ~ ., iris)
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
ridge
#find the best lambda by cross-validation
#test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
#test_set <- X[test_rows,]
#train_rows <- setdiff(seq_len(nrow(X)), test_rows)
#train_set <- X[train_rows,]
#y_test <- as.numeric(test_set %*% ridge + rnorm(n, sd=5))
#y_test <- tcrossprod(test_set, ridge)
#browser()
#y_train <- tcrossprod(train_set, ridge)
#browser()
#mse <- apply((y_train - y_test)^2, 2, mean)
#best_lambda <- lambdas[which.min(mse)]
#ridge[best_lambda*10,]
}
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- y[train_rows]
browser()
ridge(train_set, y_train_set)
}
ridge_regress(Sepal.Length ~ ., iris)
train_rows
test_rows
test_set
y_train_set
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------
#The following function is actually called
#------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
browser()
ridge(train_set, y_train_set)
}
ridge_regress(Sepal.Length ~ ., iris)
y_train_set
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------------------------------------------------------------------------
#The following function is actually called
#It takes a formula, data set, and optional set of lambdas to check and produces an optimal ridge regression
#It uses 90% of the data for training and the other 10% for cross-validation to determine the best lambda
#-------------------------------------------------------------------------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
y_test_set <- Y[test_rows]
if(identical(lambda,0)){
lambda <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambda)
regressions <- ridge(train_set, y_train_set, lambdas = lambda)
y_hat <- tcrossprod(test_set, regressions)
mse <- apply((y_hat-y_test_set)^2,2,mean)
best_L <- lambda[which.min(mse)]
return(list(best_L, regressions[best_L*10]))
}
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------------------------------------------------------------------------
#The following function is actually called
#It takes a formula, data set, and optional set of lambdas to check and produces an optimal ridge regression
#It uses 90% of the data for training and the other 10% for cross-validation to determine the best lambda
#-------------------------------------------------------------------------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
y_test_set <- Y[test_rows]
if(identical(lambda,0)){
lambda <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambda)
regressions <- ridge(train_set, y_train_set, lambdas = lambda)
y_hat <- tcrossprod(test_set, regressions)
mse <- apply((y_hat-y_test_set)^2,2,mean)
best_L <- lambda[which.min(mse)]
browser()
return(list(best_L, regressions[best_L*10]))
}
ridge_regress(Sepal.Length ~ ., iris)
best_L
source('~/Documents/BIS557/bis557/R/ridge.R')
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
#------------------------------------------------------------------------------------------------------------
#The following function is actually called
#It takes a formula, data set, and optional set of lambdas to check and produces an optimal ridge regression
#It uses 90% of the data for training and the other 10% for cross-validation to determine the best lambda
#-------------------------------------------------------------------------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
y_test_set <- Y[test_rows]
if(identical(lambda,0)){
lambda <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambda)
regressions <- ridge(train_set, y_train_set, lambdas = lambda)
y_hat <- tcrossprod(test_set, regressions)
mse <- apply((y_hat-y_test_set)^2,2,mean)
lambda[which.min(mse)]
#browser()
#return(list(best_L, regressions[best_L*10]))
}
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
browser()
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
browser()
ridge
}
ridge_regress(Sepal.Length ~ ., iris)
ridge[0]
ridge
ridge[0,]
ridge[1,]
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------------------------------------------------------------------------
#The following function is actually called
#It takes a formula, data set, and optional set of lambdas to check and produces an optimal ridge regression
#It uses 90% of the data for training and the other 10% for cross-validation to determine the best lambda
#-------------------------------------------------------------------------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
y_test_set <- Y[test_rows]
if(identical(lambda,0)){
lambda <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambda)
regressions <- ridge(train_set, y_train_set, lambdas = lambda)
y_hat <- tcrossprod(test_set, regressions)
mse <- apply((y_hat-y_test_set)^2,2,mean)
lambda[which.min(mse)]
#browser()
return(list(best_L, regressions[(best_L*10+1),]))
}
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
#------------------------------------------------------------------------------------------------------------
#The following function is actually called
#It takes a formula, data set, and optional set of lambdas to check and produces an optimal ridge regression
#It uses 90% of the data for training and the other 10% for cross-validation to determine the best lambda
#-------------------------------------------------------------------------------------------------------------
ridge_regress <- function(form, data, lambda = 0){
#make data into model matrix
X <- model.matrix(form, data,  contrasts.arg = contrasts)
Y <- matrix(data[,1],ncol = 1)
#separate into test and training data sets
test_rows <- sample.int(nrow(X), floor(nrow(X)/10))
test_set <- X[test_rows,]
train_rows <- setdiff(seq_len(nrow(X)), test_rows)
train_set <- X[train_rows,]
y_train_set <- Y[train_rows]
y_test_set <- Y[test_rows]
if(identical(lambda,0)){
lambda <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambda)
regressions <- ridge(train_set, y_train_set, lambdas = lambda)
y_hat <- tcrossprod(test_set, regressions)
mse <- apply((y_hat-y_test_set)^2,2,mean)
best_L <- lambda[which.min(mse)]
#browser()
return(list(best_L, regressions[(best_L*10+1),]))
}
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
ridge <- function(X, y, lambdas = 0){
svd_X <- svd(X)
U <- svd_X$u
V <- svd_X$v
svals <- svd_X$d
if(identical(lambdas,0)){
lambdas <- seq(from = 0, to = 10, by = 0.1)
}
k <- length(lambdas)
ridge <- matrix(nrow = k, ncol = ncol(X))
ridge <- matrix(nrow = k, ncol = ncol(X))
for(j in seq_len(k)){
D <- diag(svals / (svals^2 + lambdas[j]))
ridge[j,] <- V %*% D %*% t(U) %*% y
}
ridge
}
source('~/Documents/BIS557/bis557/R/ridge.R')
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
ridge_regress(Sepal.Length ~ ., iris)
source('~/Documents/BIS557/bis557/R/ridge.R')
source('~/Documents/BIS557/bis557/R/ridge.R')
roxygen2::roxygenise()
source('~/Documents/BIS557/bis557/R/ridge.R')
roxygen2::roxygenise()
